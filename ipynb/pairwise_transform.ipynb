{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d3b88b-ec42-47c7-8144-60efcfdac8f9",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "\n",
    "This approach had been adopted from [fa.bianp.net](https://fa.bianp.net/blog/2012/learning-to-rank-with-scikit-learn-the-pairwise-transform/)\n",
    "\n",
    "# Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfe397a-fd34-4a41-a2c5-92f4bb312bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c950db2c-fb80-4236-98ea-fcd3596a1da0",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b40e637-74dc-4c90-840a-5f11631c5126",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'cross_validation' from 'sklearn' (/usr/local/lib/python3.9/site-packages/sklearn/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpylab\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m svm, linear_model, cross_validation\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'cross_validation' from 'sklearn' (/usr/local/lib/python3.9/site-packages/sklearn/__init__.py)"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pylab as pl\n",
    "from sklearn import svm, linear_model, cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00b58afd-49c1-48ac-aee7-c39865e43292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1]\n",
      "[ True False  True False  True False  True False  True False  True False\n",
      "  True False  True False  True False  True False  True False  True False\n",
      "  True False  True False  True False  True False  True False  True False\n",
      "  True False  True False  True False  True False  True False  True False\n",
      "  True False  True False  True False  True False  True False  True False]\n",
      "\n",
      "\n",
      "[False  True False  True False  True False  True False  True False  True\n",
      " False  True False  True False  True False  True False  True False  True\n",
      " False  True False  True False  True False  True False  True False  True\n",
      " False  True False  True False  True False  True False  True False  True\n",
      " False  True False  True False  True False  True False  True False  True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "theta = np.deg2rad(60)\n",
    "w = np.array([np.sin(theta), np.cos(theta)])\n",
    "K = 20\n",
    "X = np.random.randn(K, 2)\n",
    "y = [0] * K\n",
    "for i in range(1, 3):\n",
    "    X = np.concatenate((X, np.random.randn(K, 2) + i * 4 * w))\n",
    "    y = np.concatenate((y, [i] * K))\n",
    "\n",
    "# slightly displace data corresponding to our second partition\n",
    "X[::2] -= np.array([3, 7])\n",
    "blocks = np.array([0, 1] * int(X.shape[0] / 2))\n",
    "\n",
    "#idx = (blocks == 0)\n",
    "print(X)\n",
    "#print(blocks)\n",
    "#print (idx)\n",
    "print(\"\\n\")\n",
    "#print(~idx)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdacefb7-4028-41e8-ab15-98592ddf1833",
   "metadata": {},
   "source": [
    "# Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aa715b-06b3-442d-b67a-4b2a92d671bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "theta = np.deg2rad(60)\n",
    "w = np.array([np.sin(theta), np.cos(theta)])\n",
    "K = 20\n",
    "X = np.random.randn(K, 2)\n",
    "y = [0] * K\n",
    "for i in range(1, 3):\n",
    "    X = np.concatenate((X, np.random.randn(K, 2) + i * 4 * w))\n",
    "    y = np.concatenate((y, [i] * K))\n",
    "\n",
    "# slightly displace data corresponding to our second partition\n",
    "X[::2] -= np.array([3, 7])\n",
    "blocks = np.array([0, 1] * (X.shape[0] / 2))\n",
    "\n",
    "# split into train and test set\n",
    "cv = cross_validation.StratifiedShuffleSplit(y, test_size=.5)\n",
    "train, test = iter(cv).next()\n",
    "X_train, y_train, b_train = X[train], y[train], blocks[train]\n",
    "X_test, y_test, b_test = X[test], y[test], blocks[test]\n",
    "\n",
    "# plot the result\n",
    "idx = (b_train == 0)\n",
    "pl.scatter(X_train[idx, 0], X_train[idx, 1], c=y_train[idx],\n",
    "    marker='^', cmap=pl.cm.Blues, s=100)\n",
    "pl.scatter(X_train[~idx, 0], X_train[~idx, 1], c=y_train[~idx],\n",
    "    marker='o', cmap=pl.cm.Blues, s=100)\n",
    "pl.arrow(0, 0, 8 * w[0], 8 * w[1], fc='gray', ec='gray',\n",
    "    head_width=0.5, head_length=0.5)\n",
    "pl.text(0, 1, '$w$', fontsize=20)\n",
    "pl.arrow(-3, -8, 8 * w[0], 8 * w[1], fc='gray', ec='gray',\n",
    "    head_width=0.5, head_length=0.5)\n",
    "pl.text(-2.6, -7, '$w$', fontsize=20)\n",
    "pl.axis('equal')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50f3fb3-4860-406c-9199-834d9cff5445",
   "metadata": {},
   "source": [
    "# 1st Solution (Not Optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceafe01-68d3-4970-9409-d3168e7ad4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = linear_model.Ridge(1.)\n",
    "ridge.fit(X_train, y_train)\n",
    "coef = ridge.coef_ / linalg.norm(ridge.coef_)\n",
    "\n",
    "# plot the result\n",
    "pl.scatter(X_train[idx, 0], X_train[idx, 1], c=y_train[idx],\n",
    "    marker='^', cmap=pl.cm.Blues, s=100)\n",
    "pl.scatter(X_train[~idx, 0], X_train[~idx, 1], c=y_train[~idx],\n",
    "    marker='o', cmap=pl.cm.Blues, s=100)\n",
    "pl.arrow(0, 0, 7 * coef[0], 7 * coef[1], fc='gray', ec='gray',\n",
    "    head_width=0.5, head_length=0.5)\n",
    "pl.text(2, 0, '$\\hat{w}$', fontsize=20)\n",
    "pl.axis('equal')\n",
    "pl.title('Estimation by Ridge regression')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9afa70-bfa2-46c6-aac9-bc1e2d782495",
   "metadata": {},
   "source": [
    "## Assess Quality of Model\n",
    "\n",
    "The model is a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca522d09-3217-4d8a-a809-a030f2e048f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    tau, _ = stats.kendalltau(\n",
    "        ridge.predict(X_test[b_test == i]), y_test[b_test == i])\n",
    "    print('Kendall correlation coefficient for block %s: %.5f' % (i, tau))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540aa1e5-b772-4d07-b8ee-b6484f91fa36",
   "metadata": {},
   "source": [
    "# Solution 2: Pairwise Transform\n",
    "\n",
    "As proved in (Herbrich 1999), if we consider linear ranking functions, the ranking problem can be transformed into a two-class classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5a20ef-7d5d-4381-9345-4167e5de5942",
   "metadata": {},
   "source": [
    "## Create Pairwise Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0d1a9c-3c9b-4fbb-81cf-b6621ed25374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form all pairwise combinations\n",
    "comb = itertools.combinations(range(X_train.shape[0]), 2)\n",
    "k = 0\n",
    "Xp, yp, diff = [], [], []\n",
    "for (i, j) in comb:\n",
    "    if y_train[i] == y_train[j] \\\n",
    "        or blocks[train][i] != blocks[train][j]:\n",
    "        # skip if same target or different group\n",
    "        continue\n",
    "    Xp.append(X_train[i] - X_train[j])\n",
    "    diff.append(y_train[i] - y_train[j])\n",
    "    yp.append(np.sign(diff[-1]))\n",
    "    # output balanced classes\n",
    "    if yp[-1] != (-1) ** k:\n",
    "        yp[-1] *= -1\n",
    "        Xp[-1] *= -1\n",
    "        diff[-1] *= -1\n",
    "    k += 1\n",
    "Xp, yp, diff = map(np.asanyarray, (Xp, yp, diff))\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "pl.scatter(Xp[:, 0], Xp[:, 1], c=diff, s=60, marker='o', cmap=pl.cm.Blues)\n",
    "x_space = np.linspace(-10, 10)\n",
    "pl.plot(x_space * w[1], - x_space * w[0], color='gray')\n",
    "pl.text(3, -4, '$\\{x^T w = 0\\}$', fontsize=17)\n",
    "pl.axis('equal')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c354490-17b1-419f-8d0f-b39d9946d270",
   "metadata": {},
   "source": [
    "## Train Using Support Vector Machine (RankSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fedeb6-e5d8-40b5-8d86-36b6560b5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=.1)\n",
    "clf.fit(Xp, yp)\n",
    "coef = clf.coef_.ravel() / linalg.norm(clf.coef_)\n",
    "\n",
    "# Plot the results\n",
    "pl.scatter(X_train[idx, 0], X_train[idx, 1], c=y_train[idx],\n",
    "    marker='^', cmap=pl.cm.Blues, s=100)\n",
    "pl.scatter(X_train[~idx, 0], X_train[~idx, 1], c=y_train[~idx],\n",
    "    marker='o', cmap=pl.cm.Blues, s=100)\n",
    "pl.arrow(0, 0, 7 * coef[0], 7 * coef[1], fc='gray', ec='gray',\n",
    "    head_width=0.5, head_length=0.5)\n",
    "pl.arrow(-3, -8, 7 * coef[0], 7 * coef[1], fc='gray', ec='gray',\n",
    "    head_width=0.5, head_length=0.5)\n",
    "pl.text(1, .7, '$\\hat{w}$', fontsize=20)\n",
    "pl.text(-2.6, -7, '$\\hat{w}$', fontsize=20)\n",
    "pl.axis('equal')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c1077-a4f2-4a1c-89f1-c2947f1ab099",
   "metadata": {},
   "source": [
    "## Assess Quality of Model\n",
    "\n",
    "The ranking score (Kendall tau) increases with the RankSVM model respect to linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266fb4de-3bf6-46f9-a7e2-1779b1c9afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    tau, _ = stats.kendalltau(\n",
    "        np.dot(X_test[b_test == i], coef), y_test[b_test == i])\n",
    "    print('Kendall correlation coefficient for block %s: %.5f' % (i, tau))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
